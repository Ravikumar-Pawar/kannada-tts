# ğŸµ Kannada TTS - Quick Reference Card

## ğŸ“‹ Basic Commands

### Setup
```bash
python -m venv venv
source venv/Scripts/activate       # Windows: venv\Scripts\activate
pip install -r requirements.txt
pip install torch==2.0.0 --index-url https://download.pytorch.org/whl/cu118
```

### Validation
```bash
python src/validate.py             # Check system readiness
```

### Full Pipeline
```bash
python src/data_prep.py            # ~10 min - Prepare dataset
python src/train_tacotron.py       # ~24-48 hrs - Train models
python src/inference.py            # ~30 sec - Generate speech
python src/evaluate.py             # ~5 min - Evaluate quality
```

### Quick Demo
```bash
python src/demo.py                 # Run pipeline automatically
```

---

## ğŸ” Inspection Commands

### Dataset Analysis
```python
from src.utils import DatasetUtils
stats = DatasetUtils.analyze_dataset("data/metadata.csv")
print(stats)
```

### Audio Info
```python
from src.utils import AudioUtils
info = AudioUtils.get_audio_info("output/inference/test.wav")
print(info)
```

### Model Size
```python
from src.utils import ModelUtils
size = ModelUtils.get_model_size("output/tacotron2/best_model.pth")
print(size)
```

### System Diagnostics
```python
from src.utils import SystemUtils
SystemUtils.print_diagnostics()
```

---

## ğŸ¨ Inference Examples

### Basic Synthesis
```python
from src.inference import KannadaTTSInference

engine = KannadaTTSInference("output/tacotron2/best_model.pth")
audio, sr = engine.synthesize("à²¨à²®à²¸à³à²•à²¾à²°")
```

### Emotion Synthesis
```python
# Happy
audio, sr = engine.synthesize("à²¸à³à²–à²µà²¾à²—à²¿à²¦à³†!", emotion="happy")

# Sad
audio, sr = engine.synthesize("à²¨à²¨à²—à³† à²¦à³à²ƒà²–à²µà²¾à²¯à²¿à²¤à³.", emotion="sad")

# Angry
audio, sr = engine.synthesize("à²‡à²¦à³ à²¤à²ªà³à²ªà³!", emotion="angry")

# Calm
audio, sr = engine.synthesize("à²¨à²¿à²¶à³à²šà²¿à²‚à²¤à²ªà²¡à²¿.", emotion="calm")
```

### With Assessment
```python
result = engine.assess_and_synthesize(
    text="à²•à²¨à³à²¨à²¡ TTS à²µà³à²¯à²µà²¸à³à²¥à³†",
    output_path="output/sample.wav",
    emotion="neutral"
)
print(result['quality_metrics'])
```

---

## ğŸ”Š Audio Processing

### Noise Reduction
```python
from src.inference import NoiseReductionModule

denoiser = NoiseReductionModule()
clean = denoiser.denoise(audio, method="spectral_gating")
```

### Emotion Enhancement
```python
from src.inference import EmotionEnhancementModule

enhancer = EmotionEnhancementModule()
enhanced = enhancer.apply_emotion(audio, emotion="happy")
```

### Custom Prosody
```python
modified = enhancer.enhance_prosody(
    audio,
    pitch_shift=2.0,        # +2 semitones
    duration_scale=0.9,     # 10% faster
    energy_scale=1.3        # 30% louder
)
```

### Quality Check
```python
from src.inference import SpeechQualityAssessment

assessor = SpeechQualityAssessment()
metrics = assessor.assess_quality(audio)

print(f"SNR: {metrics['snr_db']:.1f} dB")
print(f"Clarity: {metrics['intelligibility_score']:.1f}%")
```

---

## ğŸ“Š Evaluation

### Single File
```python
from src.evaluate import SpeechEvaluationMetrics
import librosa

evaluator = SpeechEvaluationMetrics()
y_ref, sr = librosa.load("reference.wav", sr=22050)
y_syn, sr = librosa.load("synthesis.wav", sr=22050)

metrics = evaluator.evaluate(y_ref, y_syn)
print(f"MCD: {metrics['mcd_mean']:.2f} dB")
print(f"SNR: {metrics['snr_db']:.1f} dB")
```

### Batch Evaluation
```bash
python src/evaluate.py
```

---

## ğŸ› ï¸ Configuration

### Default Tacotron2
```json
{
  "batch_size": 16,
  "epochs": 500,
  "encoder_hidden_size": 256,
  "decoder_hidden_size": 1024,
  "lr": 0.001
}
```

### For GPU with 8GB Memory
```json
{
  "batch_size": 8,
  "encoder_hidden_size": 128,
  "decoder_hidden_size": 512,
  "num_loader_workers": 0
}
```

### For Fast Training
```json
{
  "epochs": 100,
  "batch_size": 32,
  "encoder_hidden_size": 512,
  "decoder_hidden_size": 2048
}
```

---

## ğŸ“ File Organization

```
kannada-tts/
â”œâ”€â”€ Data Preparation
â”‚   â””â”€â”€ python src/data_prep.py
â”‚       â†’ data/metadata.csv (16,950 samples)
â”‚
â”œâ”€â”€ Training  
â”‚   â””â”€â”€ python src/train_tacotron.py
â”‚       â†’ output/tacotron2/best_model.pth
â”‚
â”œâ”€â”€ Inference
â”‚   â””â”€â”€ python src/inference.py
â”‚       â†’ output/inference/test_*.wav
â”‚
â”œâ”€â”€ Evaluation
â”‚   â””â”€â”€ python src/evaluate.py
â”‚       â†’ output/evaluation_results.json
â”‚
â”œâ”€â”€ Utilities
â”‚   â”œâ”€â”€ python src/utils.py        # Analysis tools
â”‚   â”œâ”€â”€ python src/validate.py     # Validation
â”‚   â””â”€â”€ python src/demo.py         # Demo pipeline
â”‚
â””â”€â”€ Documentation
    â”œâ”€â”€ README.md                  # Main guide
    â”œâ”€â”€ CONFIG_GUIDE.md            # Configuration
    â””â”€â”€ UPDATES.md                 # Changes
```

---

## ğŸ¯ Common Tasks

### Generate Speech from Kannada Text
```bash
python src/inference.py
# Outputs: output/inference/test_neutral.wav
#          output/inference/test_happy.wav
#          output/inference/test_calm.wav
```

### Check Dataset Quality
```python
from src.utils import DatasetUtils
df = DatasetUtils.load_metadata("data/metadata.csv")
print(df.head())
print(DatasetUtils.analyze_dataset("data/metadata.csv"))
```

### Visualize Waveform
```python
from src.utils import AudioUtils
AudioUtils.plot_waveform("output/inference/test.wav")
AudioUtils.plot_spectrogram("output/inference/test.wav")
```

### System Status
```bash
python src/validate.py
```

### Training Logs
```bash
tail -f output/training.log
tensorboard --logdir output/tacotron2/
```

---

## ğŸ”¢ Performance Targets

| Metric | Target | Typical |
|--------|--------|---------|
| MCD | < 7.0 dB | 6.2 dB |
| MSSTFT | < 2.5 dB | 1.8 dB |
| SNR | > 20 dB | 28.5 dB |
| Intelligibility | > 80% | 85% |
| Training Time | ~36 hrs | 24-48 hrs |
| Inference Speed | RTF < 0.5 | 0.25 RTF |

---

## âš¡ Optimization Tips

### Faster Training
- Increase `batch_size` (if GPU memory allows)
- Reduce `encoder_hidden_size` to 128
- Set `num_epochs` to 100-200

### Better Quality
- Increase `epochs` to 1000+
- Double model sizes (hidden dims)
- Use `hifigan` vocoder
- Increase `n_mel_channels` to 128

### Lower Memory (GPU < 8GB)
```json
{
  "batch_size": 4,
  "encoder_hidden_size": 128,
  "decoder_hidden_size": 256,
  "num_loader_workers": 0
}
```

---

## ğŸ› Troubleshooting

| Problem | Solution |
|---------|----------|
| CUDA out of memory | Reduce `batch_size` to 4-8 |
| Slow data loading | Increase `num_loader_workers` |
| Poor audio quality | Increase `epochs` and `n_mel_channels` |
| Training divergence | Reduce `lr` to 0.0005 |
| Missing dataset | Run `python src/data_prep.py` |
| Import errors | Run `python src/validate.py` |

---

## ğŸ“ Support

- **Validation:** `python src/validate.py`
- **Training logs:** `output/training.log`
- **Configuration:** `CONFIG_GUIDE.md`
- **General help:** `README.md`

---

## ğŸš€ Next Steps

1. âœ… Validate system: `python src/validate.py`
2. ğŸ“Š Prepare data: `python src/data_prep.py`
3. ğŸ“ Train models: `python src/train_tacotron.py`
4. ğŸ¤ Generate speech: `python src/inference.py`
5. ğŸ“ˆ Evaluate: `python src/evaluate.py`

---

**Last Updated:** 2026-02-28  
**Version:** 2.0 (Production Ready)
